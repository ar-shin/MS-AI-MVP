import streamlit as st
import json
from services.document_intelligence import extract_text_from_file
from services.gpt_summarizer import summarize_text
from services.gpt_summarizer import select_representative_summary
from services.chunker import chunk_text
from services.chat_def import classify_fp_coefficients
from services.similar_project_search import search_similar_projects
from services.utils import init_session_state
from services.chat_def import answer_question

# ì„¸ì…˜ ì´ˆê¸°í™”
init_session_state()

# UI êµ¬ì„±
st.set_page_config(page_title="AI ê¸°ë°˜ RFP ë¶„ì„ Agent", layout="wide")

st.markdown(
    """
    <h1 style='text-align: center; color: #003366; font-size: 2.5em;'>ğŸ¤– AI ê¸°ë°˜ RFP ë¶„ì„ Agent</h1>
    <p style='text-align: center; color: gray;'>LLM ê¸°ë°˜ ìš”ì•½, ìœ ì‚¬ í”„ë¡œì íŠ¸ ì¶”ì²œ, ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ë´‡, SWê°œë°œë¹„ ì‚°ì •ê¹Œì§€ í•œë²ˆì—!</p>
    """,
    unsafe_allow_html=True
)

st.markdown("---")

uploaded_file = st.file_uploader("ğŸ“„ RFP ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”", type=["pdf", "ppt"], key="file_upload")
prev_file = st.session_state.get("uploaded_filename")

# íŒŒì¼ ì‚­ì œ ì²´í¬
if uploaded_file is None and prev_file:
    # st.session_state["tab_option"] = "ğŸ“„ ìš”ì•½"
    init_session_state(force_reset=True)
    st.rerun()

# íŒŒì¼ ë³€ê²½ ì²´í¬
elif uploaded_file and uploaded_file.name != prev_file:
    # st.session_state["tab_option"] = "ğŸ“„ ìš”ì•½"
    init_session_state(force_reset=True)
    st.session_state["uploaded_filename"] = uploaded_file.name
    st.rerun()


st.markdown("""
<style>
div[data-testid="stRadio"] {
    display: flex;
    justify-content: center;
    align-items: center;
}

div[role="radiogroup"] > label {
    border: 1px solid #d3d3d3;
    border-radius: 8px;
    padding: 0.5em 1.2em;
    margin-right: 0.5em;
    margin-bottom: 0.3em;
    background-color: #f7f9fc;
    color: #003366;
    font-weight: 500;
    transition: 0.2s ease-in-out;
    cursor: pointer;
    box-shadow: 0 0 3px rgba(0,0,0,0.05);
}
div[role="radiogroup"] > label:hover {
    background-color: #e6f0ff;
}
div[role="radiogroup"] > label[data-selected="true"] {
    background-color: #003366;
    color: white;
    font-weight: bold;
    border-color: #003366;
}
div[data-testid="stRadio"] > label {
    display: none;
}
</style>
""", unsafe_allow_html=True)

TAB_LABELS = ["ğŸ“„ ìš”ì•½", "ğŸ’¬ ì§ˆë¬¸í•˜ê¸°", "ğŸ’²SWê°œë°œë¹„ ì‚°ì •"]
tab_option = st.radio(
    label="", 
    options=TAB_LABELS, 
    horizontal=True,
    index=TAB_LABELS.index(st.session_state.get("tab_option", "ğŸ“„ ìš”ì•½")),
    key="tab_option_radio"
)

if tab_option != st.session_state["tab_option"]:
    st.session_state["tab_option"] = tab_option
    st.rerun()

st.markdown("---")


if tab_option == "ğŸ“„ ìš”ì•½":
    if uploaded_file is None:
        st.markdown("ğŸ“¢ RFP ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ìœ ì‚¬ í”„ë¡œì íŠ¸ë¥¼ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.")

    if uploaded_file and st.session_state["chunks"] is None:
        with st.spinner("â³ ë¬¸ì„œ ë¶„ì„ ì¤‘..."):
            text = extract_text_from_file(uploaded_file)
            chunks = chunk_text(text)
            results = [summarize_text(chunk) for chunk in chunks]

            best_summary = select_representative_summary(
                results,
                embedding_model="dev-text-embedding-3-small"
            )

            st.session_state["text"] = text
            st.session_state["chunks"] = chunks
            st.session_state["summaries"] = best_summary

    if "summaries" in st.session_state and st.session_state["summaries"] is not None:
        st.subheader(f"ğŸ“Œ ìš”ì•½")
        st.write(st.session_state["summaries"])

        with st.spinner("ğŸ” ìœ ì‚¬ í”„ë¡œì íŠ¸ ê²€ìƒ‰ ì¤‘..."):
            query_summary = st.session_state["summaries"]
            similar_projects = search_similar_projects(
                query_text=query_summary,
                embedding_model="dev-text-embedding-3-small",
            )

            st.markdown("---")
            st.subheader("ğŸ§© ì°¸ê³ ìš© ìœ ì‚¬ í”„ë¡œì íŠ¸ ì¶”ì²œ")
            for idx, project in enumerate(similar_projects, 1):
                st.markdown(f"**{idx}. {project['title']}**  \n" f"- {project['chunk']}")

elif tab_option == "ğŸ’¬ ì§ˆë¬¸í•˜ê¸°":
    if uploaded_file is None:
        st.markdown("ğŸ“¢ RFP ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")

    for msg in st.session_state.messages:
        if msg["role"] == "system":
            continue
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    user_question = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

    if user_question:
        st.session_state.messages.append({"role": "user", "content": user_question})

        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘..."):
                context = "\n".join(st.session_state["chunks"])

                answer = answer_question(context, user_question)

                st.markdown(answer)

                st.session_state.messages.append({"role": "assistant", "content": answer})
    

elif tab_option == "ğŸ’²SWê°œë°œë¹„ ì‚°ì •":
    if uploaded_file is None:
        st.markdown("ğŸ“¢ RFP ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ë³´ì •ê³„ìˆ˜ë¥¼ íŒë‹¨í•˜ê³ , SWê°œë°œë¹„ë¥¼ ì‚°ì •í•´ë“œë¦½ë‹ˆë‹¤.")

    if st.session_state["chunks"] is not None:
        with st.spinner("ğŸ¤– ë³´ì •ê³„ìˆ˜ íŒë‹¨ ì¤‘..."):
            # 1. ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒë‹¨
            full_text = "\n\n".join(st.session_state["chunks"])
            coefficient_json = classify_fp_coefficients(full_text)

            st.markdown("### ğŸ“Š AI íŒë‹¨ ë³´ì •ê³„ìˆ˜ ê²°ê³¼")
            st.json(coefficient_json)

            # 2. ê³„ìˆ˜ í…Œì´ë¸” ë¡œë”©
            with open("data/fp_coefficients.json", "r", encoding="utf-8") as f:
                fp_table = json.load(f)

            # 3. ê³„ìˆ˜ ë§¤ì¹­ ë° ê³„ì‚°
            total = 1
            breakdown = []

            for category, selected_value in coefficient_json.items():
                category_table = fp_table.get(category, {})
                factor = category_table.get(selected_value)
                if factor:
                    breakdown.append(
                        f"ğŸ”¹ **{category}**: {selected_value} â†’ ê³„ìˆ˜ {factor}"
                    )
                    total *= factor
                    # count += 1
                else:
                    breakdown.append(
                        f"âš ï¸ **{category}**: '{selected_value}'ì— ëŒ€í•œ ê³„ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )

            # 4. ì¶œë ¥
            st.markdown("### âœ… ê³„ì‚° ê²°ê³¼ ìš”ì•½")
            for line in breakdown:
                st.markdown(line)

            if total > 0:
                # avg = round(total / count, 3)
                st.success(f"ğŸ’¡ ìµœì¢… ë³´ì •ê³„ìˆ˜: **{total}**")
            else:
                st.error(
                    "âŒ ê³„ì‚° ê°€ëŠ¥í•œ ê³„ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ ë˜ëŠ” ì…ë ¥ê°’ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                )

            # st.markdown("### ğŸ”§ ì‚¬ìš©ì ì„ íƒ ë³´ì •ê³„ìˆ˜ë¡œ ì´ ê°œë°œë¹„ìš© ê³„ì‚°")
            # user_selection = {}
            # for category, options in fp_table.items():
            #     gpt_default = coefficient_json.get(category, "ì• ë§¤í•¨")
            #     selected = st.selectbox(
            #         f"{category}",
            #         options=list(options.keys()) + ["ì• ë§¤í•¨"],
            #         index=(
            #             (list(options.keys()) + ["ì• ë§¤í•¨"]).index(gpt_default)
            #             if gpt_default in options
            #             else len(options)
            #         ),
            #     )
            #     user_selection[category] = selected

import streamlit as st
from services.document_intelligence import extract_text_from_file
from services.gpt_summarizer import summarize_text
from services.chunker import chunk_text
from services.fp_classifier import classify_fp_coefficients
from services.similar_project_search import search_similar_projects
from services.utils import init_session_state

# ì„¸ì…˜ ì´ˆê¸°í™”
init_session_state()

# UI êµ¬ì„±
st.title("AI ê¸°ë°˜ RFP ë¶„ì„ AGENT")
uploaded_file = st.file_uploader("ğŸ“„ RFP íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "docx"])
tab1, tab2, tab3 = st.tabs(["ğŸ“„ ìš”ì•½", "ğŸ’¬ ì§ˆë¬¸í•˜ê¸°", "ğŸ’²SWê°œë°œë¹„ ì‚°ì •"])

with tab1:
    if uploaded_file is None:
        st.markdown("ğŸ“¢ RFP ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ìœ ì‚¬ í”„ë¡œì íŠ¸ë¥¼ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.")

    if uploaded_file and "chunks" not in st.session_state:
        with st.spinner("â³ ë¬¸ì„œ ë¶„ì„ ì¤‘..."):
            text = extract_text_from_file(uploaded_file)
            chunks = chunk_text(text)
            results = [summarize_text(chunk) for chunk in chunks]

            st.session_state["text"] = text
            st.session_state["chunks"] = chunks
            st.session_state["summaries"] = results

    if "summaries" in st.session_state and st.session_state["summaries"] is not None:
        for i, res in enumerate(st.session_state["summaries"], 1):
            st.subheader(f"ğŸ“Œ ìš”ì•½ {i}")
            st.write(res)

        with st.spinner("ğŸ” ìœ ì‚¬ í”„ë¡œì íŠ¸ ê²€ìƒ‰ ì¤‘..."):
            query_summary = "\n".join(st.session_state["summaries"])
            similar_projects = search_similar_projects(
                query_text=query_summary,
                embedding_model="text-embedding-3-small",  # í˜¹ì€ ë°°í¬í•œ ëª¨ë¸ ì´ë¦„
            )

            st.subheader("ğŸ§© ì°¸ê³ ìš© ìœ ì‚¬ í”„ë¡œì íŠ¸ ì¶”ì²œ")
            for idx, project in enumerate(similar_projects, 1):
                st.markdown(f"**{idx}. {project['title']}**  \n" f"- {project['chunk']}")

with tab2:
    if uploaded_file is None:
        st.markdown("ğŸ“¢ RFP ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")
    
    

with tab3:
    if uploaded_file is None:
        st.markdown("ğŸ“¢ RFP ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ë³´ì •ê³„ìˆ˜ë¥¼ íŒë‹¨í•˜ê³ , SWê°œë°œë¹„ë¥¼ ì‚°ì •í•´ë“œë¦½ë‹ˆë‹¤.")

    if "chunks" in st.session_state and st.session_state["chunks"] is not None:
        with st.spinner("ğŸ¤– ë³´ì •ê³„ìˆ˜ íŒë‹¨ ì¤‘..."):
            from services.fp_classifier import classify_fp_coefficients
            import json

            # 1. ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒë‹¨
            full_text = "\n\n".join(st.session_state["chunks"])
            coefficient_json = classify_fp_coefficients(full_text)

            st.markdown("### ğŸ“Š AI íŒë‹¨ ë³´ì •ê³„ìˆ˜ ê²°ê³¼")
            st.json(coefficient_json)

            # 2. ê³„ìˆ˜ í…Œì´ë¸” ë¡œë”©
            with open("data/fp_coefficients.json", "r", encoding="utf-8") as f:
                fp_table = json.load(f)

            # 3. ê³„ìˆ˜ ë§¤ì¹­ ë° ê³„ì‚°
            total = 0
            # count = 0
            breakdown = []
            for category, selected_value in coefficient_json.items():
                category_table = fp_table.get(category, {})
                factor = category_table.get(selected_value)
                if factor:
                    breakdown.append(
                        f"ğŸ”¹ **{category}**: {selected_value} â†’ ê³„ìˆ˜ {factor}"
                    )
                    total *= factor
                    # count += 1
                else:
                    breakdown.append(
                        f"âš ï¸ **{category}**: '{selected_value}'ì— ëŒ€í•œ ê³„ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )

            # 4. ì¶œë ¥
            st.markdown("### âœ… ê³„ì‚° ê²°ê³¼ ìš”ì•½")
            for line in breakdown:
                st.markdown(line)

            if total > 0:
                # avg = round(total / count, 3)
                st.success(f"ğŸ’¡ ìµœì¢… ë³´ì •ê³„ìˆ˜: **{total}**")
            else:
                st.error(
                    "âŒ ê³„ì‚° ê°€ëŠ¥í•œ ê³„ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ ë˜ëŠ” ì…ë ¥ê°’ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                )

            # st.markdown("### ğŸ”§ ì‚¬ìš©ì ì„ íƒ ë³´ì •ê³„ìˆ˜ë¡œ ì´ ê°œë°œë¹„ìš© ê³„ì‚°")
            # user_selection = {}
            # for category, options in fp_table.items():
            #     gpt_default = coefficient_json.get(category, "ì• ë§¤í•¨")
            #     selected = st.selectbox(
            #         f"{category}",
            #         options=list(options.keys()) + ["ì• ë§¤í•¨"],
            #         index=(
            #             (list(options.keys()) + ["ì• ë§¤í•¨"]).index(gpt_default)
            #             if gpt_default in options
            #             else len(options)
            #         ),
            #     )
            #     user_selection[category] = selected
